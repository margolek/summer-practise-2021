{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/margolek/TensorFlow-Object-Detection/blob/master/TFODCourse-main/1.%20Image%20Collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWISEVMbO7zR"
   },
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_FiuqXfMO7zX"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Use unique identificators to collect name photos in unique way\n",
    "We need opencv in order to connect camera via RTSP protocole\n",
    "Time module allow us set time delay between photo capturing\n",
    "We need opencv in order to connect camera via RTSP protocole\n",
    "Matplotlib - most popular Python package to create matlab-like figures\n",
    "The OS module in Python provides functions for interacting with the operating system\n",
    "\n",
    "'''\n",
    "import uuid\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfbWGnwZO7zY"
   },
   "source": [
    "# 2. Define Images to Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "07--ioCbO7zZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "We only need to define one label because hole is one thing that we need to detect\n",
    "We also define images batch size\n",
    "\n",
    "'''\n",
    "\n",
    "label = 'hole'\n",
    "image_batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUqEVd57O7zb"
   },
   "source": [
    "# 3. Create folders and collect  images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "yj34k950O7zb",
    "outputId": "26e6a149-b365-4de9-edcd-932d15273233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b862336c03a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#         cv2.imwrite(imgname, frame[220:270,180:470])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#         cv2.imshow('frame', frame[220:270,180:470])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m320\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m370\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m310\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frame'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m320\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m370\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m310\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "IMAGES_PATH = os.path.join('TensorflowObjectDetectionAPI','mydataset')\n",
    "\n",
    "# Check if defined model name exist (Useful when we collect extra data after first collecting)\n",
    "if not os.path.exists(IMAGES_PATH):\n",
    "  !mkdir {IMAGES_PATH}\n",
    "\n",
    "RTSP = os.environ.get('RTSP_ADDRESS')\n",
    "cap = cv2.VideoCapture(RTSP)\n",
    "\n",
    "for n in range(1,image_batch_size+1):\n",
    "    print(f'Nr. {n}')\n",
    "    ret, frame = cap.read()\n",
    "    # UUID4 (Random ID)\n",
    "    imgname = os.path.join(IMAGES_PATH,label+'.'+'{}.jpg'.format(str(uuid.uuid4().int)))\n",
    "\n",
    "#         cv2.imwrite(imgname, frame[220:270,180:470])\n",
    "#         cv2.imshow('frame', frame[220:270,180:470])\n",
    "    cv2.imwrite(imgname, frame[320:370,310:600])\n",
    "    cv2.imshow('frame', frame[320:370,310:600])\n",
    "    time.sleep(1)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "1. Image Collection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow-api",
   "language": "python",
   "name": "tensorflow-api"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
